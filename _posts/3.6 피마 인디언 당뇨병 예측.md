
* 피마 인디언 당뇨병 데이터 세트를 이용해 당뇨병 여부를 판단하는 머신러닝 예측 모델을 수립하고 평가 지표를 적용
* 피마 인디언 당뇨병 데이터 세트 설명
    * 북아메리카 피마 지역 원주민의 Type-2 당뇨병 결과 데이터
    * 보통 당뇨 원인으로 식습관과 유전을 꼽음
    * 피마 지역은 고립된 지역에서 인디언 고유의 혈통이 재속돼 왔지만, 20세기 후반에 들어서면서 서구화된 식습관으로 많은 당뇨 환자가 생김
* 피마 인디언 당뇨병 데이터 세트 피처

피처명|설명
:-----|:---
Pregnancies|임신 횟수
Glucose|포도당 부하 검사 수치
BloodPressure|혈압(mm Hg)
SkinThickness|팔 삼두근 뒤쪽의 피하지방 측정값(mm)
Insulin|혈청 인슐린(mu U/ml)
BMI|체질량지수(체중(kg)/(키(m))^2)
DiabetesPedigreeFunction|당뇨 내력 가중치 값
Age| 나이
Outcome|클래스 결정 값(0 또는 1)

## 1. 데이터 불러오기
* 데이터 불러온 후 Outcome 클래스 결정값의 분포와 데이터를 확인
    * 768개 데이터 중 Negative 값 0이 500개, Positive 값 1이 268개로 Negative가 상대적으로 많음


```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score
from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

diabetes_data = pd.read_csv('diabetes.csv')
print(diabetes_data['Outcome'].value_counts())
diabetes_data.head(3)
```

    0    500
    1    268
    Name: Outcome, dtype: int64
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pregnancies</th>
      <th>Glucose</th>
      <th>BloodPressure</th>
      <th>SkinThickness</th>
      <th>Insulin</th>
      <th>BMI</th>
      <th>DiabetesPedigreeFunction</th>
      <th>Age</th>
      <th>Outcome</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>6</td>
      <td>148</td>
      <td>72</td>
      <td>35</td>
      <td>0</td>
      <td>33.6</td>
      <td>0.627</td>
      <td>50</td>
      <td>1</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1</td>
      <td>85</td>
      <td>66</td>
      <td>29</td>
      <td>0</td>
      <td>26.6</td>
      <td>0.351</td>
      <td>31</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>8</td>
      <td>183</td>
      <td>64</td>
      <td>0</td>
      <td>0</td>
      <td>23.3</td>
      <td>0.672</td>
      <td>32</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



* feature의 타입과 Null 개수 확인
    * Null 값은 없으며 피처의 타입은 모두 숫자형
    * 임신 횟수, 나이와 같은 숫자형 피처와 당뇨 검사 수치 피처로 구성된 특징으로 볼 때 별도의 피처 인코딩은 필요 없어 보임


```python
diabetes_data.info( )
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 768 entries, 0 to 767
    Data columns (total 9 columns):
    Pregnancies                 768 non-null int64
    Glucose                     768 non-null int64
    BloodPressure               768 non-null int64
    SkinThickness               768 non-null int64
    Insulin                     768 non-null int64
    BMI                         768 non-null float64
    DiabetesPedigreeFunction    768 non-null float64
    Age                         768 non-null int64
    Outcome                     768 non-null int64
    dtypes: float64(2), int64(7)
    memory usage: 54.1 KB
    

## 2. 예측 모델 생성
* 로지스틱 회귀를 이용해 예측 모델을 생성


```python
# 수정된 get_clf_eval() 함수 
def get_clf_eval(y_test, pred=None, pred_proba=None):
    confusion = confusion_matrix( y_test, pred)
    accuracy = accuracy_score(y_test , pred)
    precision = precision_score(y_test , pred)
    recall = recall_score(y_test , pred)
    f1 = f1_score(y_test,pred)
    # ROC-AUC 추가 
    roc_auc = roc_auc_score(y_test, pred_proba)
    print('오차 행렬')
    print(confusion)
    # ROC-AUC print 추가
    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\
    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))

```


```python
def precision_recall_curve_plot(y_test=None, pred_proba_c1=None):
    # threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출. 
    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)
    
    # X축을 threshold값으로, Y축은 정밀도, 재현율 값으로 각각 Plot 수행. 정밀도는 점선으로 표시
    plt.figure(figsize=(8,6))
    threshold_boundary = thresholds.shape[0]
    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')
    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')
    
    # threshold 값 X 축의 Scale을 0.1 단위로 변경
    start, end = plt.xlim()
    plt.xticks(np.round(np.arange(start, end, 0.1),2))
    
    # x축, y축 label과 legend, 그리고 grid 설정
    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')
    plt.legend(); plt.grid()
    plt.show()
```

* 데이터 세트를 피처 데이터 세트와 클래서 데이터 세트로 나누고 학습 데이터 세트와 테스트 데이터 세트로 분리
* 로지스틱 회귀를 이용해 예측을 수행하고 앞 예제에서 사용한 유틸리티 함수인 `get_clf_eval()`, `get_eval_by_threshold()`, `precision_recall_curve_plot()`을 이용해 성능 평가 지표를 출력하고 재현율 곡선을 시각화


```python
# 피처 데이터 세트 X, 레이블 데이터 세트 y를 추출. 
# 맨 끝이 Outcome 컬럼으로 레이블 값임. 컬럼 위치 -1을 이용해 추출 
X = diabetes_data.iloc[:, :-1]
y = diabetes_data.iloc[:, -1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 156, stratify=y)

# 로지스틱 회귀로 학습,예측 및 평가 수행. 
lr_clf = LogisticRegression()
lr_clf.fit(X_train , y_train)
pred = lr_clf.predict(X_test)
pred_proba = lr_clf.predict_proba(X_test)[:, 1]

get_clf_eval(y_test , pred, pred_proba)
```

    오차 행렬
    [[87 13]
     [22 32]]
    정확도: 0.7727, 정밀도: 0.7111, 재현율: 0.5926,    F1: 0.6465, AUC:0.8083
    

    C:\Users\KwonChulmin\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
      FutureWarning)
    

* 예측 정확도가 77.27%, 재현율은 59.26%로 측정됨
* 전체 데이터의 65%가 Negative이므로 정확도보다는 재현율 선능에 조금 더 초점을 맞출 것

**정밀도 재현율 곡선을 보고 임계값별 정밀도와 재현율 값의 변화 확인**
* `precision_recall_curve_plot()` 함수를 이용
* 재현율 곡선을 보면 임계값을 0.42로 낮추면 정밀도와 재현율이 어느 정도 균형을 맞출 것 같음. 하지만 두 개의 지표 모두 0.7이 안 되는 수치로 보임
* 두 지표의 값이 낮으므로 임계값을 니위적으로 조작하기 전 다시 데이터 값을 점검


```python
pred_proba_c1 = lr_clf.predict_proba(X_test)[:, 1]
precision_recall_curve_plot(y_test, pred_proba_c1)
```


![png](https://github.com/slchoi01/slchoi01.github.io/tree/master/image/pymldg/ch3/output_12_0.png)


**데이터 점검**
* `describe()` 메서드를 호출해 피처 값의 분포도를 살펴봄
* `diabetes_data.describe()` 데이터 값을 보면 min() 값이 0으로 돼 있는 피처가 많음
    * Glucose 피처는 포도당 수치인데 min 값이 0인 것은 말이 되지 않음


```python
diabetes_data.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pregnancies</th>
      <th>Glucose</th>
      <th>BloodPressure</th>
      <th>SkinThickness</th>
      <th>Insulin</th>
      <th>BMI</th>
      <th>DiabetesPedigreeFunction</th>
      <th>Age</th>
      <th>Outcome</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>count</td>
      <td>768.000000</td>
      <td>768.000000</td>
      <td>768.000000</td>
      <td>768.000000</td>
      <td>768.000000</td>
      <td>768.000000</td>
      <td>768.000000</td>
      <td>768.000000</td>
      <td>768.000000</td>
    </tr>
    <tr>
      <td>mean</td>
      <td>3.845052</td>
      <td>120.894531</td>
      <td>69.105469</td>
      <td>20.536458</td>
      <td>79.799479</td>
      <td>31.992578</td>
      <td>0.471876</td>
      <td>33.240885</td>
      <td>0.348958</td>
    </tr>
    <tr>
      <td>std</td>
      <td>3.369578</td>
      <td>31.972618</td>
      <td>19.355807</td>
      <td>15.952218</td>
      <td>115.244002</td>
      <td>7.884160</td>
      <td>0.331329</td>
      <td>11.760232</td>
      <td>0.476951</td>
    </tr>
    <tr>
      <td>min</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.078000</td>
      <td>21.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <td>25%</td>
      <td>1.000000</td>
      <td>99.000000</td>
      <td>62.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>27.300000</td>
      <td>0.243750</td>
      <td>24.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <td>50%</td>
      <td>3.000000</td>
      <td>117.000000</td>
      <td>72.000000</td>
      <td>23.000000</td>
      <td>30.500000</td>
      <td>32.000000</td>
      <td>0.372500</td>
      <td>29.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <td>75%</td>
      <td>6.000000</td>
      <td>140.250000</td>
      <td>80.000000</td>
      <td>32.000000</td>
      <td>127.250000</td>
      <td>36.600000</td>
      <td>0.626250</td>
      <td>41.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <td>max</td>
      <td>17.000000</td>
      <td>199.000000</td>
      <td>122.000000</td>
      <td>99.000000</td>
      <td>846.000000</td>
      <td>67.100000</td>
      <td>2.420000</td>
      <td>81.000000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>



* Glucose 피처의 히스토그램을 확인해 보면 0 값이 일정 수준 존재하는 것을 알 수 있음


```python
plt.hist(diabetes_data['Glucose'], bins=10)
```




    (array([  5.,   0.,   4.,  32., 156., 211., 163.,  95.,  56.,  46.]),
     array([  0. ,  19.9,  39.8,  59.7,  79.6,  99.5, 119.4, 139.3, 159.2,
            179.1, 199. ]),
     <a list of 10 Patch objects>)




![png](https://github.com/slchoi01/slchoi01.github.io/tree/master/image/pymldg/ch3/output_16_1.png)


* `min()` 값이 0으로 돼 있는 피처에 대해 0 값의 건수 및 전체 데이터 건수 대비 몇 퍼센트의 비율로 존재하는지 확인
    * 확인할 피처: 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI'
    * 'Pregnancies'는 출산 횟수를 의미하므로 제외


```python
# 0값을 검사할 피처명 리스트 객체 설정
zero_features = ['Glucose', 'BloodPressure','SkinThickness','Insulin','BMI']

# 전체 데이터 건수
total_count = diabetes_data['Glucose'].count()

# 피처별로 반복 하면서 데이터 값이 0 인 데이터 건수 추출하고, 퍼센트 계산
for feature in zero_features:
    zero_count = diabetes_data[diabetes_data[feature] == 0][feature].count()
    print('{0} 0 건수는 {1}, 퍼센트는 {2:.2f} %'.format(feature, zero_count, 100*zero_count/total_count))

```

    Glucose 0 건수는 5, 퍼센트는 0.65 %
    BloodPressure 0 건수는 35, 퍼센트는 4.56 %
    SkinThickness 0 건수는 227, 퍼센트는 29.56 %
    Insulin 0 건수는 374, 퍼센트는 48.70 %
    BMI 0 건수는 11, 퍼센트는 1.43 %
    

* SkinThickness와 Insulin의 0 값은 각각 전체의 29.56%, 48.7%로 많은 편. 전체 데이터 건수가 만지 않기 때문에 이들 데이터를 삭제할 경우 학습을 효과적으로 수행하기 어려울 것 같으므로 위 피처의 0 값을 평균값으로 대체


```python
# zero_features 리스트 내부에 저장된 개별 피처들에 대해서 0값을 평균 값으로 대체
diabetes_data[zero_features]=diabetes_data[zero_features].replace(0, diabetes_data[zero_features].mean())
```

* 0 값을 평균값으로 대체한 데이터 세트에 피처 스케일링을 적용해 변환
    * 로지스틱 회귀의 경우 일반적으로 숫자 데이터에 스케일링을 적용하는 것이 좋음
* 이후 다시 학습/테스트 데이터 세트로 나누고 로지스틱 회귀를 적용해 성능 평가 지표 확인


```python
X = diabetes_data.iloc[:, :-1]
y = diabetes_data.iloc[:, -1]

# StandardScaler 클래스를 이용해 피처 데이터 세트에 일괄적으로 스케일링 적용
scaler = StandardScaler( )
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state = 156, stratify=y)

# 로지스틱 회귀로 학습, 예측 및 평가 수행. 
lr_clf = LogisticRegression()
lr_clf.fit(X_train , y_train)
pred = lr_clf.predict(X_test)
pred_proba = lr_clf.predict_proba(X_test)[:, 1]

get_clf_eval(y_test , pred, pred_proba)
```

    오차 행렬
    [[90 10]
     [21 33]]
    정확도: 0.7987, 정밀도: 0.7674, 재현율: 0.6111,    F1: 0.6804, AUC:0.8433
    

    C:\Users\KwonChulmin\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
      FutureWarning)
    

**분류 결정 임계값을 변화시키면서 재현율 값의 성능 수치가 어느 정도 개선되는지 확인**
* 임계값을 0.3 ~ 0.5까지 0.03씩 변화시키면서 재현율과 다른 평가 지표의 값 변화를 출력
* 임계값에 따른 평가 수치 출력은 앞에서 사용한 `get_eval_by_threshold()` 함수를 이용


```python
from sklearn.preprocessing import Binarizer

def get_eval_by_threshold(y_test , pred_proba_c1, thresholds):
    # thresholds 리스트 객체내의 값을 차례로 iteration하면서 Evaluation 수행.
    for custom_threshold in thresholds:
        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1) 
        custom_predict = binarizer.transform(pred_proba_c1)
        print('임곗값:',custom_threshold)
        get_clf_eval(y_test , custom_predict, pred_proba_c1)
```


```python
thresholds = [0.3 , 0.33 ,0.36,0.39, 0.42 , 0.45 ,0.48, 0.50]
pred_proba = lr_clf.predict_proba(X_test)
get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds )
```

    임곗값: 0.3
    오차 행렬
    [[65 35]
     [11 43]]
    정확도: 0.7013, 정밀도: 0.5513, 재현율: 0.7963,    F1: 0.6515, AUC:0.8433
    임곗값: 0.33
    오차 행렬
    [[71 29]
     [11 43]]
    정확도: 0.7403, 정밀도: 0.5972, 재현율: 0.7963,    F1: 0.6825, AUC:0.8433
    임곗값: 0.36
    오차 행렬
    [[76 24]
     [15 39]]
    정확도: 0.7468, 정밀도: 0.6190, 재현율: 0.7222,    F1: 0.6667, AUC:0.8433
    임곗값: 0.39
    오차 행렬
    [[78 22]
     [16 38]]
    정확도: 0.7532, 정밀도: 0.6333, 재현율: 0.7037,    F1: 0.6667, AUC:0.8433
    임곗값: 0.42
    오차 행렬
    [[84 16]
     [18 36]]
    정확도: 0.7792, 정밀도: 0.6923, 재현율: 0.6667,    F1: 0.6792, AUC:0.8433
    임곗값: 0.45
    오차 행렬
    [[85 15]
     [18 36]]
    정확도: 0.7857, 정밀도: 0.7059, 재현율: 0.6667,    F1: 0.6857, AUC:0.8433
    임곗값: 0.48
    오차 행렬
    [[88 12]
     [19 35]]
    정확도: 0.7987, 정밀도: 0.7447, 재현율: 0.6481,    F1: 0.6931, AUC:0.8433
    임곗값: 0.5
    오차 행렬
    [[90 10]
     [21 33]]
    정확도: 0.7987, 정밀도: 0.7674, 재현율: 0.6111,    F1: 0.6804, AUC:0.8433
    

**결과 확인**
* 정확도와 정밀도를 희생하고 재현율을 높이는데 가장 좋은 임계값으 0.33으로, 재현율 값이 0.7963이지만 정밀도가 0.5972로 매우 저조해졌으니 극단적 선택으로 보임
* 임계값 0.48이 전체적인 성능 평가 지표를 유지하면서 재현율을 약간 향상시키는 좋은 임계값으로 보임
* 임계값이 0.48일 경우 정확도는 0.7987, 정밀도는 0.7447, 재현율은 0.6481, F1 스코어는 0.6931, ROC AUC는 0.8433

**임계값을 0.48로 낮춘 상태에서 다시 예측 수행**
* 앞에서 학습된 로지스틱 회귀 모델을 이용해 임계값을 낮춘 상태에서 다시 예측을 수행
* 사이킷런의 `predict()` 메서드는 ㅣㅁ계값을 마음대로 변환할 수 없으므로 별도의 로직으로 구해야함
    * Binarizer 클래스를 이용해 `predict_proba()`로 추출한 예측 결과 확률 값을 변환해 변경된 임계값에 따른 예측 클래스 값을 구해볼 것


```python
# 임곗값를 0.48로 설정한 Binarizer 생성
binarizer = Binarizer(threshold=0.48)

# 위에서 구한 lr_clf의 predict_proba() 예측 확률 array에서 1에 해당하는 컬럼값을 Binarizer변환. 
pred_th_048 = binarizer.fit_transform(pred_proba[:, 1].reshape(-1,1)) 

get_clf_eval(y_test , pred_th_048, pred_proba[:, 1])

```
